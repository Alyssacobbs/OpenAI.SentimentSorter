## Question 1

What is the most common sentiment observed in your sample of 50 reviews according to your OpenAI labeled data?

[The most common sentiment observed in my sample of reviews is negative.]

## Question 2

How reliable do you believe these labels are? Look at the respective labels OpenAI has generated for specific reviews, does it seem like the large language model accurately described the user's review? What risk do model hallucinations introduce into this analysis?

[I believe these labels are somewhat reliable. When I read through the reviews some of the OpenAI labels are accurate while others are not. Using OpenAI can be helpful but results may vary based on the system_prompt used. Hallucinations can occur between users especially when someone includes more details in the system_prompts versus less details. Ultimately, the small differences in the code can influence the large-language-models' output although both users may request the model to act as a sentiment sorter.]

## Question 3

Using the most common sentiment, what would you recommend to this Coconut Water producer to improve customer satisfaction? Should they continue to pursue current market/product outcomes, or does there exist an opportunity for this business to improve its product?

[The most common sentiment is negative suggesting that the producer of this water should undergo some changes to improve customer satisfaction. Most users dislike the the taste of the water, so modifying the receipe and performing taste test surveys may help the producer maintain repeat customers.]
